{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this approach takes a VERY long time and, at first glance, doesn't give a fundamental advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import auxiliary as aux\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_1_0</th>\n",
       "      <th>F_1_1</th>\n",
       "      <th>F_1_2</th>\n",
       "      <th>F_1_3</th>\n",
       "      <th>F_1_4</th>\n",
       "      <th>F_1_5</th>\n",
       "      <th>F_1_6</th>\n",
       "      <th>F_1_7</th>\n",
       "      <th>F_1_8</th>\n",
       "      <th>F_1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>F_4_5</th>\n",
       "      <th>F_4_6</th>\n",
       "      <th>F_4_7</th>\n",
       "      <th>F_4_8</th>\n",
       "      <th>F_4_9</th>\n",
       "      <th>F_4_10</th>\n",
       "      <th>F_4_11</th>\n",
       "      <th>F_4_12</th>\n",
       "      <th>F_4_13</th>\n",
       "      <th>F_4_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.354591</td>\n",
       "      <td>-0.464038</td>\n",
       "      <td>2.304115</td>\n",
       "      <td>0.734486</td>\n",
       "      <td>1.696395</td>\n",
       "      <td>0.136285</td>\n",
       "      <td>-0.518344</td>\n",
       "      <td>0.502640</td>\n",
       "      <td>-1.852504</td>\n",
       "      <td>-0.500665</td>\n",
       "      <td>...</td>\n",
       "      <td>3.744152</td>\n",
       "      <td>0.794438</td>\n",
       "      <td>0.265185</td>\n",
       "      <td>-0.561809</td>\n",
       "      <td>0.196480</td>\n",
       "      <td>0.373434</td>\n",
       "      <td>6.206995</td>\n",
       "      <td>3.809505</td>\n",
       "      <td>1.236486</td>\n",
       "      <td>1.182055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.380940</td>\n",
       "      <td>-0.499626</td>\n",
       "      <td>-0.418548</td>\n",
       "      <td>1.911725</td>\n",
       "      <td>-0.826130</td>\n",
       "      <td>-1.715371</td>\n",
       "      <td>-0.577091</td>\n",
       "      <td>-1.041486</td>\n",
       "      <td>0.596067</td>\n",
       "      <td>-0.363425</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.895826</td>\n",
       "      <td>-0.738275</td>\n",
       "      <td>2.361818</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>-0.271882</td>\n",
       "      <td>5.232157</td>\n",
       "      <td>-4.218259</td>\n",
       "      <td>-2.724883</td>\n",
       "      <td>-0.063775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256023</td>\n",
       "      <td>-1.059874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345678</td>\n",
       "      <td>1.513814</td>\n",
       "      <td>1.243864</td>\n",
       "      <td>-0.509648</td>\n",
       "      <td>-0.800481</td>\n",
       "      <td>-0.115945</td>\n",
       "      <td>0.595777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.252834</td>\n",
       "      <td>0.472496</td>\n",
       "      <td>2.491386</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>-0.260682</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.116457</td>\n",
       "      <td>-2.131747</td>\n",
       "      <td>3.661499</td>\n",
       "      <td>-0.131576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.728420</td>\n",
       "      <td>-2.432399</td>\n",
       "      <td>-2.453602</td>\n",
       "      <td>-0.020509</td>\n",
       "      <td>0.333397</td>\n",
       "      <td>0.086049</td>\n",
       "      <td>-1.787601</td>\n",
       "      <td>0.667011</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-2.217847</td>\n",
       "      <td>...</td>\n",
       "      <td>2.004600</td>\n",
       "      <td>-4.664806</td>\n",
       "      <td>-0.847211</td>\n",
       "      <td>-0.264249</td>\n",
       "      <td>0.664334</td>\n",
       "      <td>-0.557868</td>\n",
       "      <td>8.499483</td>\n",
       "      <td>-4.738799</td>\n",
       "      <td>-3.054611</td>\n",
       "      <td>0.494152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590212</td>\n",
       "      <td>-0.066127</td>\n",
       "      <td>0.468009</td>\n",
       "      <td>-1.096038</td>\n",
       "      <td>0.119399</td>\n",
       "      <td>-1.809710</td>\n",
       "      <td>0.466358</td>\n",
       "      <td>-0.053196</td>\n",
       "      <td>-0.580320</td>\n",
       "      <td>-1.143500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976937</td>\n",
       "      <td>2.558883</td>\n",
       "      <td>3.377724</td>\n",
       "      <td>0.846891</td>\n",
       "      <td>0.696032</td>\n",
       "      <td>0.554121</td>\n",
       "      <td>-5.979714</td>\n",
       "      <td>-2.869631</td>\n",
       "      <td>3.733057</td>\n",
       "      <td>-0.722943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F_1_0     F_1_1     F_1_2     F_1_3     F_1_4     F_1_5     F_1_6  \\\n",
       "row_id                                                                         \n",
       "0      -0.354591 -0.464038  2.304115  0.734486  1.696395  0.136285 -0.518344   \n",
       "1       1.380940 -0.499626 -0.418548  1.911725 -0.826130 -1.715371 -0.577091   \n",
       "2       0.256023 -1.059874       NaN  0.345678  1.513814  1.243864 -0.509648   \n",
       "3      -0.728420 -2.432399 -2.453602 -0.020509  0.333397  0.086049 -1.787601   \n",
       "4       0.590212 -0.066127  0.468009 -1.096038  0.119399 -1.809710  0.466358   \n",
       "\n",
       "           F_1_7     F_1_8     F_1_9  ...     F_4_5     F_4_6     F_4_7  \\\n",
       "row_id                                ...                                 \n",
       "0       0.502640 -1.852504 -0.500665  ...  3.744152  0.794438  0.265185   \n",
       "1      -1.041486  0.596067 -0.363425  ... -2.895826 -0.738275  2.361818   \n",
       "2      -0.800481 -0.115945  0.595777  ...  2.252834  0.472496  2.491386   \n",
       "3       0.667011  0.761564 -2.217847  ...  2.004600 -4.664806 -0.847211   \n",
       "4      -0.053196 -0.580320 -1.143500  ...  0.976937  2.558883  3.377724   \n",
       "\n",
       "           F_4_8     F_4_9    F_4_10    F_4_11    F_4_12    F_4_13    F_4_14  \n",
       "row_id                                                                        \n",
       "0      -0.561809  0.196480  0.373434  6.206995  3.809505  1.236486  1.182055  \n",
       "1      -0.060753  0.727249 -0.271882  5.232157 -4.218259 -2.724883 -0.063775  \n",
       "2       0.353381 -0.260682 -0.000833 -0.116457 -2.131747  3.661499 -0.131576  \n",
       "3      -0.264249  0.664334 -0.557868  8.499483 -4.738799 -3.054611  0.494152  \n",
       "4       0.846891  0.696032  0.554121 -5.979714 -2.869631  3.733057 -0.722943  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essence of the method:\n",
    "- fit ALS to get similar objects\n",
    "- impute with statistics of `N` similar objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'factors': 25,\n",
    "    'regularization': 0.001,\n",
    "    'iterations': 15,\n",
    "    'calculate_training_loss': True,\n",
    "    'use_gpu': False,\n",
    "    'random_state': 23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "    def __init__(self, **params):\n",
    "        self.__als = AlternatingLeastSquares(**params)\n",
    "        self.__items = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.__als.fit(csr_matrix(df))\n",
    "        self.__size = df.index.size\n",
    "        return self\n",
    "\n",
    "    def get_own_similars(self, uid, *, frac=1.0, threshold=0.7):\n",
    "        \"\"\"\n",
    "        :param uid - single object id\n",
    "        :param frac - use a fraction of sample\n",
    "        \"\"\"\n",
    "        uid_list, proba = self.__als.similar_users(uid, N=int(self.__size * frac))\n",
    "        return uid_list[1:][proba[1:] > threshold]\n",
    "\n",
    "    def get_similars(self, uid, *, frac=1.0, threshold=0.7):\n",
    "        \"\"\" This provides LOTS OF DATA (each-to-each)\n",
    "        :param uid - object ids collection\n",
    "        :param frac - subsample ratio of the training instance\n",
    "        \"\"\"\n",
    "        _uid = uid if isinstance(uid, Iterable) else [uid, ]\n",
    "        for idx in _uid:\n",
    "            uid_list, proba = self.__als.similar_users(idx, N=int(self.__size * frac))\n",
    "            similars = uid_list[1:][proba[1:] > threshold]\n",
    "            yield idx, similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05e42e032b944c197fefb86ad09dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "sim = Similarity(**param).fit(aux.subset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_stats(df, model, frac=1.0, threshold=0.9, aggfunc='mean'):\n",
    "    \"\"\" Collect statistics based on similar items for each item containing NaN\n",
    "    :param df - full original dataset\n",
    "    :param model - Similarity model\n",
    "    :param frac - subsample ratio of the training instance\n",
    "    :param threshold - minimal accepted score\n",
    "    :param aggfunc - data aggregation function\n",
    "\n",
    "    IMPORTANT! frac=1.0 will take a very long time on large datasets\n",
    "    \"\"\"\n",
    "    nan_rows = df.isna().any(axis=1)\n",
    "    index = df[nan_rows].index\n",
    "    similars_iterator = model.get_similars(index, frac=frac, threshold=threshold)\n",
    "    print(f'fraction size: {int(frac * index.size)}')\n",
    "\n",
    "    sim_stats = {}\n",
    "    for idx, similars in tqdm(similars_iterator, total=index.size):\n",
    "        sim_stats[idx] = df.loc[similars, :].agg(aggfunc)\n",
    "    return pd.DataFrame(sim_stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 1e-4     # kaggle 1.42: 63 similars is very low\n",
    "stats = similar_stats(aux.data, sim, frac=frac)\n",
    "stats.to_csv(f'data/similar_stats_frac_{frac}.csv')\n",
    "# NOTE it still contains NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction size: 31761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 635226/635226 [10:56:50<00:00, 16.12it/s]  \n"
     ]
    }
   ],
   "source": [
    "frac = 0.05\n",
    "stats = similar_stats(aux.data, sim, frac=frac)\n",
    "stats.to_csv(f'data/similar_stats_frac_{frac}.csv')\n",
    "# NOTE it still contains NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.05\n",
    "stats = pd.read_csv(f'data/similar_stats_frac_{frac}.csv', index_col='Unnamed: 0')\n",
    "predicted = aux.data.fillna(stats)\n",
    "predicted = predicted.fillna(predicted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collect individual stats for each item containing NaN based on similar items with specified cosine similarity threshold\n",
    "# # NOTE this will take ~35hours\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# threshold = 0.9\n",
    "\n",
    "# nan_rows = aux.data.isna().any(axis=1)\n",
    "# index = aux.data[nan_rows].index\n",
    "# stats = {}\n",
    "\n",
    "# for row_idx in tqdm(aux.data[nan_rows].index):\n",
    "#     exclude_own = aux.subset[2].index != row_idx\n",
    "#     target = aux.subset[2].loc[exclude_own, :].copy()\n",
    "#     # calculate cosine similarity between this and all other items\n",
    "#     sim = cosine_similarity([aux.subset[2].loc[row_idx, :]], target)\n",
    "#     target['cosine'] = sim[0]\n",
    "#     # apply threshold and sort\n",
    "#     mask = target['cosine'] > threshold\n",
    "#     similars = target.loc[mask, 'cosine'].sort_values(ascending=False).index\n",
    "#     # get statistics\n",
    "#     stats[row_idx] = aux.data.loc[similars, :].mean()\n",
    "\n",
    "# stats = pd.DataFrame(stats).T\n",
    "# stats.to_csv('data/similars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.utils import parallel_backend\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# threshold = 0.9\n",
    "# nan_rows = aux.data.isna().any(axis=1)\n",
    "# index = aux.data[nan_rows].index\n",
    "\n",
    "\n",
    "# def calc_stats(idx, base, target, *, threshold=0.9):\n",
    "#     \"\"\"\n",
    "#     :param idx - index of current item\n",
    "#     :param base - dataset for cosine similarity calculation\n",
    "#     :param target - dataset for statistics calculation\n",
    "#     :threshold - minimal accepted cosine value\n",
    "#     \"\"\"\n",
    "#     # calculate cosine similarity between this and all other items\n",
    "#     cosine = cosine_similarity([base.loc[idx, :]], base)[0]\n",
    "#     sim = pd.Series(cosine, index=base.index, name='cosine')\n",
    "#     # apply threshold and sort\n",
    "#     mask = (sim > threshold) & (sim.index != idx)\n",
    "#     similars = sim[mask].sort_values(ascending=False).index\n",
    "\n",
    "#     # get statistics\n",
    "#     return idx, target.loc[similars, :].mean()\n",
    "\n",
    "# def impute_cosine(base, target):\n",
    "#     with parallel_backend('threading'):\n",
    "#         result = dict(Parallel(n_jobs=-1)(delayed(calc_stats)(idx, base, target) for idx in tqdm(index[:100])))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = pd.DataFrame(impute_cosine(aux.subset[2], aux.subset[1])).T\n",
    "# stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine with columns autodetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils import parallel_backend\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def calc_stats(idx, df, threshold=0.9):\n",
    "    \"\"\"\n",
    "    :param idx - index of current item\n",
    "    :param df - original dataset\n",
    "    :threshold - minimal accepted cosine value\n",
    "    \"\"\"\n",
    "    # get columns without NaN\n",
    "    cols = df.columns[~df.isna().any()]\n",
    "\n",
    "    # calculate cosine similarity between this and all other items\n",
    "    cosine = cosine_similarity([df.loc[idx, cols]], df[cols])[0]\n",
    "    sim = pd.Series(cosine, index=df.index, name='cosine')\n",
    "    # apply threshold and sort\n",
    "    mask = (sim > threshold) & (sim.index != idx)\n",
    "    similars = sim[mask].sort_values(ascending=False).index\n",
    "    # get statistics\n",
    "    return idx, df.loc[similars, :].mean()\n",
    "\n",
    "def impute_cosine(df, threshold=0.9, backend='threading'):\n",
    "    nan_rows = df.isna().any(axis=1)\n",
    "    index = df[nan_rows].index\n",
    "\n",
    "    with parallel_backend(backend):\n",
    "        result = dict(Parallel(n_jobs=-1)(delayed(calc_stats)(idx, df, threshold) for idx in tqdm(index)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(impute_cosine(aux.data, threshold=0.7, backend='loky')).T\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = aux.subset[2].to_numpy().copy()\n",
    "# for idx in tqdm(aux.subset[2].index[:18]):\n",
    "#     cosine_similarity([aux.subset[2].iloc[0]], arr)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.save_submission(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
