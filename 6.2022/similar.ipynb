{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this approach takes a VERY long time and, at first glance, doesn't give a fundamental advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import auxiliary as aux\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils import parallel_backend\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essence of the method:\n",
    "- fit ALS to get similar objects\n",
    "- impute with statistics of `N` similar objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'factors': 25,\n",
    "    'regularization': 0.001,\n",
    "    'iterations': 15,\n",
    "    'calculate_training_loss': True,\n",
    "    'use_gpu': False,\n",
    "    'random_state': 23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "    def __init__(self, **params):\n",
    "        self.__als = AlternatingLeastSquares(**params)\n",
    "        self.__items = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.__als.fit(csr_matrix(df))\n",
    "        self.__size = df.index.size\n",
    "        return self\n",
    "\n",
    "    def get_own_similars(self, uid, *, frac=1.0, threshold=0.7):\n",
    "        \"\"\"\n",
    "        :param uid - single object id\n",
    "        :param frac - use a fraction of sample\n",
    "        \"\"\"\n",
    "        uid_list, proba = self.__als.similar_users(uid, N=int(self.__size * frac))\n",
    "        return uid_list[1:][proba[1:] > threshold]\n",
    "\n",
    "    def get_similars(self, uid, *, frac=1.0, threshold=0.7):\n",
    "        \"\"\" This provides LOTS OF DATA (each-to-each)\n",
    "        :param uid - object ids collection\n",
    "        :param frac - subsample ratio of the training instance\n",
    "        \"\"\"\n",
    "        _uid = uid if isinstance(uid, Iterable) else [uid, ]\n",
    "        for idx in _uid:\n",
    "            uid_list, proba = self.__als.similar_users(idx, N=int(self.__size * frac))\n",
    "            similars = uid_list[1:][proba[1:] > threshold]\n",
    "            yield idx, similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05e42e032b944c197fefb86ad09dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "sim = Similarity(**param).fit(aux.subset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_stats(df, model, frac=1.0, threshold=0.9, aggfunc='mean'):\n",
    "    \"\"\" Collect statistics based on similar items for each item containing NaN\n",
    "    :param df - full original dataset\n",
    "    :param model - Similarity model\n",
    "    :param frac - subsample ratio of the training instance\n",
    "    :param threshold - minimal accepted score\n",
    "    :param aggfunc - data aggregation function\n",
    "\n",
    "    IMPORTANT! frac=1.0 will take a very long time on large datasets\n",
    "    \"\"\"\n",
    "    nan_rows = df.isna().any(axis=1)\n",
    "    index = df[nan_rows].index\n",
    "    similars_iterator = model.get_similars(index, frac=frac, threshold=threshold)\n",
    "    print(f'fraction size: {int(frac * index.size)}')\n",
    "\n",
    "    sim_stats = {}\n",
    "    for idx, similars in tqdm(similars_iterator, total=index.size):\n",
    "        sim_stats[idx] = df.loc[similars, :].agg(aggfunc)\n",
    "    return pd.DataFrame(sim_stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 1e-4     # kaggle 1.42: 63 similars is very low\n",
    "stats = similar_stats(aux.data, sim, frac=frac)\n",
    "stats.to_csv(f'data/similar_stats_frac_{frac}.csv')\n",
    "# NOTE it still contains NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction size: 31761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 635226/635226 [10:56:50<00:00, 16.12it/s]  \n"
     ]
    }
   ],
   "source": [
    "frac = 0.05\n",
    "stats = similar_stats(aux.data, sim, frac=frac)\n",
    "stats.to_csv(f'data/similar_stats_frac_{frac}.csv')\n",
    "# NOTE it still contains NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.05\n",
    "stats = pd.read_csv(f'data/similar_stats_frac_{frac}.csv', index_col='Unnamed: 0')\n",
    "predicted = aux.data.fillna(stats)\n",
    "predicted = predicted.fillna(predicted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MANUAL\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# chunksize = 100\n",
    "# threshold = None\n",
    "# k = 50\n",
    "# df = aux.data.iloc[:1000]\n",
    "\n",
    "# use_cols = df.columns[~df.isna().any()]     # select columns without NaN\n",
    "# nan_rows = df.isna().any(axis=1)\n",
    "\n",
    "# stats = []\n",
    "# df_size = df[nan_rows].index.size\n",
    "# chunk_count = df_size // chunksize + (1 if df_size % chunksize else 0)\n",
    "# # iterate through chunks\n",
    "# for start_idx in tqdm(range(0, df_size, chunksize), total=chunk_count):\n",
    "#     end_idx = start_idx + chunksize\n",
    "#     cosine = cosine_similarity(df.loc[nan_rows, use_cols].iloc[start_idx:end_idx], df[use_cols])\n",
    "\n",
    "#     if threshold is not None:       # collect by threshold\n",
    "#         mask = cosine > threshold       # apply threshold\n",
    "#         np.fill_diagonal(mask, False)   # exclude ownes\n",
    "#         # stats.extend(list(map(lambda m: df[m].mean().to_list(), mask)))\n",
    "#         stats.extend(np.apply_along_axis(lambda m: df[m].mean(), 1, mask))\n",
    "#     elif k is not None:     # collect by k nearest\n",
    "#         # stats.extend(list(map(lambda c: df.iloc[np.argsort(c)[::-1][1:]].head(k).mean(), cosine)))\n",
    "#         stats.extend(np.apply_along_axis(lambda c: df.iloc[np.argsort(c)[::-1][1:]].head(k).mean(), 1, cosine))\n",
    "# pd.DataFrame(stats, index=df[nan_rows].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csim = aux.CosineSimilarity(aux.data.iloc[:50000])\n",
    "# stats = csim.calculate(threshold=0.7, backend='threading')\n",
    "stats = csim.calculate(k=50000, backend=None, chunksize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csim = aux.CosineSimilarity(aux.data.iloc[:50000])\n",
    "# stats = csim.calculate(threshold=0.7, backend='threading')\n",
    "stats = csim.calculate(k=50000, backend='loky', chunksize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 25410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 176/25410 [31:39<12:18:39,  1.76s/it] "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csim = aux.CosineSimilarity(aux.data)\n",
    "# stats = csim.calculate(threshold=0.7, backend='threading')\n",
    "stats = csim.calculate(k=50000, backend='loky', chunksize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter_default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a8a6843721b26098060b435da282c6499d0f0384483463012990926fcfc80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
