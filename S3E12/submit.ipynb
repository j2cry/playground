{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn.preprocessing as pre\n",
    "from transforming import WithSelected, Apply, Calc, Select, TypeRecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_source = source.drop(columns=['id', 'target'])\n",
    "y = source.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 69)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = ['gravity', 'ph', 'osmo', 'cond', 'urea', 'calc']\n",
    "pipe = make_pipeline(\n",
    "    # is_norma features\n",
    "    # Calc('1*((1.008 < gravity) & (gravity < 1.030))', to='gravity_is_norma'),\n",
    "    # Calc('1*(urea <= 35)', to='urea_is_norma'),\n",
    "    # Calc('1*((2.5 < calc) & (calc < 7.5))', to='calc_is_norma'),\n",
    "\n",
    "    # pH-like\n",
    "    Calc('-np.log10(calc * 10e-6)', to='pCalc'),\n",
    "    Calc('-np.log10(urea * 10e-6)', to='pUr'),\n",
    "    Calc('-np.log10(osmo)', to='pOs'),\n",
    "    Calc('-np.log10(cond)', to='pCond'),\n",
    "    # Calc('pCalc - ph', to='pCalc_ph_diff'),\n",
    "    # Calc('pUr - ph', to='pUr_ph_diff'),\n",
    "\n",
    "    # prod & ratio\n",
    "    Calc('gravity / ph', to='gravity_ph_rate'),\n",
    "    Calc('gravity * ph', to='gravity_ph_prod'),\n",
    "    Calc('gravity * osmo', to='gravity_osmo_prod'),\n",
    "    Calc('gravity / calc', to='gravity_calc_rate'),\n",
    "    Calc('osmo / cond', to='osmo_cond_rate'),\n",
    "    Calc('osmo * urea', to='osmo_urea_prod'),\n",
    "    Calc('osmo * ph', to='osmo_ph_prod'),\n",
    "    Calc('(cond * urea) / ph', to='cond_urea_prod_ph_rate'),\n",
    "    Calc('cond * calc', to='cond_calc_prod'),\n",
    "    Calc('(gravity * osmo) / urea', to='gravity_osmo_prod_urea_rate'),\n",
    "\n",
    "    # Calc('calc / urea', to='calc_urea_rate'),\n",
    "    # Calc('calc / ph', to='calc_ph_rate'),\n",
    "    Calc('pOs / gravity', to='pOs_gravity_rate'),\n",
    "    Calc('pOs / ph', to='pOs_ph_rate'),\n",
    "    Calc('gravity / ph', to='gravity_ph_rate'),\n",
    "    Calc('gravity / pCalc', to='gravity_pCalc_rate'),\n",
    "    Calc('pCond / ph', to='pCond_ph_rate'),\n",
    "    Calc('pCond / pCalc', to='pCond_pCalc_rate'),\n",
    "    Calc('pCond / pUr', to='pCond_pUr_rate'),\n",
    "\n",
    "    # Calc('(osmo * gravity) / (cond * ph)', to='osmo_gravity_prod_cond_ph_prod_rate'),\n",
    "    # Calc('cond / (urea * calc)', to='cond_(urea_calc_prod)_rate'),\n",
    "\n",
    "    # Calc('', to=''),\n",
    "    # Calc('', to=''),\n",
    "\n",
    "    # power\n",
    "    WithSelected(None, 'pow')(\n",
    "    # WithSelected(original, 'pow')(\n",
    "        pre.PowerTransformer()\n",
    "    ),\n",
    "    # categirues/binaries\n",
    "    WithSelected(original, suffix='bins')(\n",
    "    # WithSelected(lambda columns: [col for col in columns if 'norma' not in col and 'pow' not in col], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(7, encode='ordinal', strategy='kmeans')\n",
    "    ),\n",
    "    # analysis\n",
    "    Apply(\n",
    "        # estimator=LinearDiscriminantAnalysis(),\n",
    "        # locpipe=pre.Normalizer(),\n",
    "        estimator=LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "        locpipe=pre.StandardScaler(),\n",
    "        # on=lambda columns: [col for col in columns if 'pow' in col],\n",
    "        to='lda',\n",
    "        as_proba=True\n",
    "    ),\n",
    "    Apply(\n",
    "        estimator=KNeighborsClassifier(7, leaf_size=30, n_jobs=-1),\n",
    "        to='neighbours',\n",
    "        as_proba=True\n",
    "    ),\n",
    "    # Apply(\n",
    "    #     estimator=IsolationForest(n_estimators=10, max_samples='auto', warm_start=True, bootstrap=True, n_jobs=-1, random_state=17),\n",
    "    #     locpipe=pre.Normalizer(),\n",
    "    #     to='isolation'\n",
    "    # ),\n",
    "    # calculations with generated features\n",
    "    Calc('neighbours / calc', to='ngb_calc_rate'),\n",
    "    Calc('lda / calc', to='lda_calc_rate'),\n",
    "    Calc('neighbours / ph', to='ngb_ph_rate'),\n",
    "    Calc('lda / ph', to='lda_ph_rate'),\n",
    "    Calc('neighbours / gravity', to='ngb_gravity_rate'),\n",
    "    Calc('lda / gravity', to='lda_gravity_rate'),\n",
    "    # Calc('neighbours / lda', to='ngb_lda_rate'),\n",
    "    Calc('(osmo / gravity) * lda', to='osmo_gravity_rate_lda_weighted'),\n",
    "\n",
    "    Calc('(calc * urea / ph) * lda', to='ion_lda_prod'),\n",
    "    Calc('(calc * urea / ph) * neighbours', to='ion_ngb_prod'),\n",
    "\n",
    "    TypeRecast(\n",
    "        int=lambda columns: [col for col in columns if 'bins' in col],\n",
    "    )\n",
    "    \n",
    "    # Select(original, mode='drop'),\n",
    ")\n",
    "\n",
    "X = pipe.fit_transform(X_source, y)\n",
    "X_test = pipe.transform(test.drop(columns=['id']))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332230623818525"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_lgbm = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9099480151228734"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_cb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364839319470699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_xgb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9237476370510397"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mix\n",
    "pred = np.mean([pred_lgbm, pred_cb, pred_xgb], axis=0)\n",
    "roc_auc_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__submit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.target = estimator.predict_proba(X_test).T[1]\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT MIX\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "estimators = (\n",
    "    LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11),\n",
    "    CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False),\n",
    "    XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23),\n",
    ")\n",
    "\n",
    "proba = []\n",
    "for est in estimators:\n",
    "    est.fit(X, y)\n",
    "    proba.append(est.predict_proba(X_test).T[1])\n",
    "\n",
    "submission.target = np.mean(proba, axis=0)\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
