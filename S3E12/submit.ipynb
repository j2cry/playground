{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn.preprocessing as pre\n",
    "from transforming import WithSelected, DFPowerTransform, Apply, Calc, Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_source = source.drop(columns=['id', 'target'])\n",
    "y = source.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = ['gravity', 'ph', 'osmo', 'cond', 'urea', 'calc']\n",
    "pipe = make_pipeline(\n",
    "    Calc('calc * urea', to='ion_prod'),\n",
    "    Calc('calc / urea', to='ion_rate'),\n",
    "    # Calc('osmo / gravity', to='osmo_gravity_rate'),\n",
    "    Calc('calc / ph', to='calc_ph_rate'),\n",
    "    \n",
    "    WithSelected(None, 'pow')(\n",
    "        DFPowerTransform()\n",
    "    ),\n",
    "    WithSelected(['calc', 'ph', 'gravity'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(7, encode='onehot', strategy='kmeans')\n",
    "    ),\n",
    "\n",
    "    Apply(\n",
    "        # estimator=LinearDiscriminantAnalysis(),\n",
    "        # locpipe=pre.Normalizer(),\n",
    "        estimator=LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "        locpipe=pre.StandardScaler(),\n",
    "        # on=lambda columns: [col for col in columns if 'pow' in col],\n",
    "        to='lda',\n",
    "        as_proba=True\n",
    "    ),\n",
    "    Apply(\n",
    "        estimator=KNeighborsClassifier(7, leaf_size=30, n_jobs=-1),\n",
    "        to='neighbours',\n",
    "        as_proba=True\n",
    "    ),\n",
    "    Apply(\n",
    "        estimator=IsolationForest(n_estimators=10, max_samples='auto', warm_start=True, bootstrap=True, n_jobs=-1, random_state=17),\n",
    "        locpipe=pre.Normalizer(),\n",
    "        to='isolation'\n",
    "    ),\n",
    "\n",
    "    Calc('neighbours / calc', to='ngb_calc_rate'),\n",
    "    Calc('lda / calc', to='lda_calc_rate'),\n",
    "    Calc('neighbours / ph', to='ngb_ph_rate'),\n",
    "    Calc('lda / ph', to='lda_ph_rate'),\n",
    "    Calc('neighbours / gravity', to='ngb_gravity_rate'),\n",
    "    Calc('lda / gravity', to='lda_gravity_rate'),\n",
    "\n",
    "    Calc('neighbours / lda', to='ngb_lda_rate'),\n",
    "\n",
    "    Select(['lda_gravity_rate', 'lda', 'lda_ph_rate', 'ngb_calc_rate', 'neighbours', \n",
    "            'ngb_gravity_rate', 'ngb_ph_rate', 'ngb_lda_rate', 'lda_calc_rate', 'ion_rate_pow', \n",
    "            'calc_pow', 'ph_pow', 'ion_rate', 'ion_prod_pow', 'gravity', \n",
    "            'cond_pow', 'cond', 'calc', 'calc_ph_rate', 'ph_bins_2'])\n",
    ")\n",
    "\n",
    "\n",
    "X = pipe.fit_transform(X_source, y)\n",
    "X_test = pipe.transform(test.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210066162570888"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_lgbm = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995746691871455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_cb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317225897920606"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_xgb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9198487712665406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mix\n",
    "pred = np.mean([pred_lgbm, pred_cb, pred_xgb], axis=0)\n",
    "roc_auc_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__submit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.target = estimator.predict_proba(X_test).T[1]\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT MIX\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "estimators = (\n",
    "    LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11),\n",
    "    CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False),\n",
    "    XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23),\n",
    ")\n",
    "\n",
    "proba = []\n",
    "for est in estimators:\n",
    "    est.fit(X, y)\n",
    "    proba.append(est.predict_proba(X_test).T[1])\n",
    "\n",
    "submission.target = np.mean(proba, axis=0)\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
