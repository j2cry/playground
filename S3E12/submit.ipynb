{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn.preprocessing as pre\n",
    "from transforming import WithSelected, DFPowerTransform, Apply, Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_source = source.drop(columns=['id', 'target'])\n",
    "y = source.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = ['gravity', 'ph', 'osmo', 'cond', 'urea', 'calc']\n",
    "pipe = make_pipeline(\n",
    "    WithSelected(original, 'pow')(\n",
    "        DFPowerTransform()\n",
    "    ),\n",
    "    WithSelected(['gravity', 'gravity_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(7, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "    WithSelected(['ph', 'ph_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(7, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "    WithSelected(['osmo', 'osmo_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(10, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "    WithSelected(['cond', 'cond_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(5, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "    WithSelected(['urea', 'urea_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(10, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "    WithSelected(['calc', 'calc_pow'], suffix='bins')(\n",
    "        pre.KBinsDiscretizer(5, encode='ordinal', strategy='quantile')\n",
    "    ),\n",
    "\n",
    "    # Apply(\n",
    "    #     estimator=KNeighborsClassifier(7, leaf_size=30, n_jobs=-1),\n",
    "    #     to='neighbours'\n",
    "    # ),\n",
    "    Apply(\n",
    "        estimator=LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "        locpipe=pre.Normalizer(),\n",
    "        # on=lambda columns: [col for col in columns if 'pow' in col],\n",
    "        to='lda'\n",
    "    ),\n",
    "    Apply(\n",
    "        estimator=KNeighborsClassifier(7, leaf_size=30, n_jobs=-1),\n",
    "        to='neighbours'\n",
    "    ),\n",
    "    Apply(\n",
    "        estimator=IsolationForest(n_estimators=20, max_samples='auto', warm_start=True, bootstrap=True, n_jobs=-1, random_state=17),\n",
    "        locpipe=pre.Normalizer(),\n",
    "        to='isolation'\n",
    "    ),\n",
    "    # Drop(original),\n",
    "    # Drop([col for col in X.columns if 'calc' in col])\n",
    ")\n",
    "\n",
    "X = pipe.fit_transform(X_source, y)\n",
    "X_test = pipe.transform(test.drop(columns=['id']))\n",
    "\n",
    "pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029182419659735"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_lgbm = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727788279773155"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_cb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040170132325143"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT\n",
    "estimator = XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23)\n",
    "estimator.fit(X, y)\n",
    "\n",
    "pred_xgb = estimator.predict_proba(X).T[1]\n",
    "roc_auc_score(y, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8969754253308129"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mix\n",
    "pred = np.mean([pred_lgbm, pred_cb, pred_xgb], axis=0)\n",
    "roc_auc_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__submit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.target = estimator.predict_proba(X_test).T[1]\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT MIX\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "estimators = (\n",
    "    LGBMClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, n_jobs=-1, random_state=11),\n",
    "    CatBoostClassifier(iterations=250, learning_rate=0.01, depth=3, random_state=11, verbose=False, allow_writing_files=False),\n",
    "    XGBClassifier(n_estimators=250, learning_rate=0.01, max_depth=3, random_state=23),\n",
    ")\n",
    "\n",
    "proba = []\n",
    "for est in estimators:\n",
    "    est.fit(X, y)\n",
    "    proba.append(est.predict_proba(X_test).T[1])\n",
    "\n",
    "submission.target = np.mean(proba, axis=0)\n",
    "submission.to_csv(f'submission_{dt.datetime.now().replace(microsecond=0)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
